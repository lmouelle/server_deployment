---

# Download and configure the bitwarden CLI program
# This only exists to pull secrets on user creation/setup that
# require refreshes like TOTP 2fa. In all other cases, prefer
# one time secrets setup on deployment within ansible with ansible-vault
# or the ansible-bitwarden plugin. I may not need TOTP 2fa refreshes,
# so disabling this for now. Will try just initial setup for rclone

# - name: Get the bw cli program
#   become: true
#   become_user: "{{ username }}"
#   ansible.builtin.get_url:
#     url: https://vault.bitwarden.com/download/?app=cli&platform=linux
#     dest: "~/.local/bin/bw"
#     mode: '500'
#     decompress: true
#     group: "{{ username }}"
#     owner: "{{ username }}"

# - name: Setup bw CLI
#   become: true
#   become_user: "{{ username }}"
#   register: bw_cli_login_result
#   environment:
#     # TODO: Set these env vars on ansible-deploy for automated auth
#     BW_CLIENTID:
#     BW_CLIENTSECRET:
#   ansible.builtin.command:
#     cmd: "bw --nointeraction --raw login"
#     creates: "~/.config/Bitwarden CLI/data.json"

# TODO: Initialize the target repos if they do not exist

# TODO: Containerize restic, so I can just use podman secrets flow everywhere
# Make systemd timer but make the associated service for the timer a quadlet .service file
# The quadlet's entry point is restic check, restic backup or restic forget
# Mount data dir readonly, with small z perms and noexec
# Have my timer run each entrypoint as a diff .service/quadlet that run sequentially, depending on prev success?
# Or... my timer triggers a backup_script.service, which runs podman exec ... $entrypoint within the script?
# Former is more complicated and gives me nothing but failures for distinct stages in systemctl --failed
# Also a second timer to check if proton/rclone config is stale and needs to be refreshed. Or refresh unconditionally every N hours?

# Make all users system users this time with no login shell and a home dir on /data drive?
# Then make this backup service in the data user just backup the entire /data drive, including their home dirs
# which will include any state. Some secrets will be in the backups (deluge state includes auth file as is) but that's fine,
# the backups are encrypted.

- name: Create rclone config for proton remote backend
  become: true
  vars_files: secrets/secret_ids.ansible.yml
  become_user: "{{ username }}"
  environment:
    RCLONE_PROTONDRIVE_USERNAME: "{{ lookup('bitwarden.secrets.lookup', proton_passwd) }}"
    RCLONE_PROTONDRIVE_PASSWORD: "{{ lookup('bitwarden.secrets.lookup', proton_username) }}"
    RCLONE_PROTONDRIVE_2FA: "{{ lookup('bitwarden.secrets.lookup', 'fb93e5ea-23b0-4e31-8d61-b18a004b8e77') }}"
  ansible.builtin.command:
    creates: ~/.config/rclone/rclone.conf
    cmd: "rclone config create --non-interactive {{ backup_remote_name }} protondrive"

- name: Ensure backup container
  become: true
  become_user: torrents
  vars:
    configs:
      backup:
        entrypoint: "backup /data -vv"
        quadlet_opt: "Before=post_backup_check"
      post_backup_check:
        entrypoint: check
        quadlet_opt: "After=backup"
      forget:
        entrypoint: "forget --keep-daily 7 --keep-hourly 48 --prune"
        quadlet_opt: "After=post_backup_check"
      post_forget_check:
        entrypoint: check
        quadlet_opt: "After=forget"
  loop: "{{ lookup('ansible.builtin.dict', configs) }}"
  containers.podman.podman_container:
    name: "{{ item.key }}"
    image: ghcr.io/restic/restic
    state: quadlet
    hostname: "{{ inventory_hostname }}"
    secrets:
      - "wasabi_media_repo,type=env,target=RESTIC_REPOSITORY"
      - "restic_passwd_media,type=env,target=RESTIC_PASSWORD"
      - "wasabi_access_key_id,type=env,target=AWS_ACCESS_KEY_ID"
      - "wasabi_access_key,type=env,target=AWS_SECRET_ACCESS_KEY"
    volume: "{{ data_dir }}:/data:Z,ro,noexec"
    entrypoint: "{{ item.value.entrypoint }}"
    quadlet_options:
      - |
        [Install]
        WantedBy=default.target
        {{ item.value.quadlet_opt }}

- name: Generate script for data sync
  become: true
  become_user: root
  ansible.builtin.copy:
    dest: "~/sync.sh"
    group: "{{ username }}"
    owner: "{{ username }}"
    mode: '500'
    validate: bash -n %s
    content: |
      #!/usr/bin/bash
      set -euo pipefail
      export HISTCONTROL=ignorespace

      # copy does not propogate deletes from local to remote, sync does
      # bisync is experimental and propogates deletes from remote to local
      # copy for now while testing, consider sync if I start to accumulate garbage
      rclone copy {{ backup_remote_name }}:nas-data -vv
