---

# TODO: Containerize restic, so I can just use podman secrets flow everywhere
# Make systemd timer but make the associated service for the timer a quadlet .service file
# The quadlet's entry point is restic check, restic backup or restic forget
# Mount data dir readonly, with small z perms and noexec
# Have my timer run each entrypoint as a diff .service/quadlet that run sequentially, depending on prev success?
# Or... my timer triggers a backup_script.service, which runs podman exec ... $entrypoint within the script?
# Former is more complicated and gives me nothing but failures for distinct stages in systemctl --failed
# Also a second timer to check if proton/rclone config is stale and needs to be refreshed. Or refresh unconditionally every N hours?

# Make all users system users this time with no login shell and a home dir on /data drive?
# Then make this backup service in the data user just backup the entire /data drive, including their home dirs
# which will include any state. Some secrets will be in the backups (deluge state includes auth file as is) but that's fine,
# the backups are encrypted.

- name: Define 2fa secret in podman
  no_log: true
  become: true
  become_user: "{{ username }}"
  containers.podman.podman_secret:
    name: proton_code
    data: "{{ raw_proton_code }}"
    state: present

- name: Ensure sync container config
  become: true
  become_user: "{{ username }}"
  containers.podman.podman_container:
    name: "config"
    image: rclone/rclone
    state: quadlet
    hostname: "{{ inventory_hostname }}"
    secrets:
      - "proton_passwd,type=env,target=RCLONE_PROTONDRIVE_PASSWORD"
      - "proton_username,type=env,target=RCLONE_PROTONDRIVE_USERNAME"
      - "proton_code,type=env,target=RCLONE_PROTONDRIVE_2FA"
    volume:
      - "~/.config/:/.config/:z"
    entrypoint: "config create --non-interactive {{ backup_remote_name }} protondrive"
    quadlet_options:
      - |
        [Install]
        WantedBy=default.target
        Type=oneshot
        RemainAfterExit=yes
        WantedBy=data_sync.service

- name: Create the restic repo if it does not exist
  become: true
  become_user: "{{ username }}"
  register: restic_init_result
  failed_when: "'config file already exists' not in restic_init_result.stdout"
  containers.podman.podman_container:
    image: ghcr.io/restic/restic
    name: init_data
    state: quadlet
    secrets:
      - "wasabi_media_repo,type=env,target=RESTIC_REPOSITORY"
      - "restic_passwd_media,type=env,target=RESTIC_PASSWORD"
      - "wasabi_access_key_id,type=env,target=AWS_ACCESS_KEY_ID"
      - "wasabi_access_key,type=env,target=AWS_SECRET_ACCESS_KEY"
    entrypoint: "init"
    quadlet_options:
      - |
        [Install]
        WantedBy=default.target
        Type=oneshot
        RemainAfterExit=yes
        WantedBy=backup_data.service
        WantedBy=forget_data.service
        WantedBy=check_data.service

- name: Ensure backup containers
  become: true
  become_user: "{{ username }}"
  vars:
    configs:
      backup_data:
        entrypoint: "backup {{ data_dir }} -v"
        quadlet_opt: Before=check_data
      check_data:
        entrypoint: check
        quadlet_opt: |
          After=backup_data
          After=forget_data
      forget_data:
        entrypoint: forget --keep-daily 7 --keep-hourly 48 --prune
        quadlet_opt: Before=check_data
  loop: "{{ lookup('ansible.builtin.dict', configs) }}"
  containers.podman.podman_container:
    name: "{{ item.key }}"
    image: ghcr.io/restic/restic
    state: quadlet
    hostname: "{{ inventory_hostname }}"
    secrets:
      - "wasabi_media_repo,type=env,target=RESTIC_REPOSITORY"
      - "restic_passwd_media,type=env,target=RESTIC_PASSWORD"
      - "wasabi_access_key_id,type=env,target=AWS_ACCESS_KEY_ID"
      - "wasabi_access_key,type=env,target=AWS_SECRET_ACCESS_KEY"
    volume: "{{ data_dir }}:/data:z,ro,noexec"
    entrypoint: "{{ item.value.entrypoint }}"
    quadlet_options:
      - |
        [Install]
        WantedBy=default.target
        Type=oneshot
        {{ item.value.quadlet_opt }}

- name: Ensure the sync service container
  become: true
  become_user: "{{ username }}"
  containers.podman.podman_container:
    name: data_sync
    image: rclone/rclone
    state: quadlet
    # Note: copy never deletes files on target, sync does. bisync deletes on both. Experiment with them
    entrypoint: "copy {{ data_dir }} {{ backup_remote_name }}:{{ backup_sync_container_name }} -v"
    volume:
      - "~/.config/:/.config/:z"
    quadlet_options:
      - |
        [Service]
        Type=oneshot

- name: Generate timers for data and backup sync
  become: true
  become_user: "{{ username }}"
  loop: data_sync backup_data
  ansible.builtin.copy:
    dest: "~/.config/systemd/user/{{ item }}.timer"
    group: "{{ username }}"
    owner: "{{ username }}"
    mode: '600'
    content: |
      [Timer]
      OnCalendar=daily
      Persistent=true

      [Install]
      WantedBy=timers.target
